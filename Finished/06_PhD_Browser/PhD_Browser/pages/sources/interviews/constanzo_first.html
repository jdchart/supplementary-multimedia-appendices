<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    
    <link rel="stylesheet" type="text/css" href="/style/reset.css">
    <link rel="stylesheet" type="text/css" href="/style/main.css">
    
    <title>Constanzo - Interview #1</title>

    <script src="https://d3js.org/d3.v4.js" SameSite=None></script>
    <script src="/scripts/howler/howler.core.js" SameSite=None></script>
    
    <script src="/scripts/flumuco_head.js" 
            audio_urls='[]' ></script>

</head>
<body>

        <div id="top_menu"></div>
        <script src="/scripts/top_menu.js"></script>

        <div id="header_player"></div>
        <script src="/scripts/header_player.js" 
                header_div_id="header_player"></script>

    <div id="actual_page_body">

        <h1>Interview With Rodrigo Constanzo</h1>
        <h4>Conducted by Owen Green, 24<sup>th</sup> April, 2018.</h4>

        <hr>

        <video controls><source src="/video/constanzo_green_interview.mov" type="video/mp4">Loading video...</video>

        <hr>

        <p>
            <br><br>
            <span style="font-style: italic;">How do you make music, and how did you get started? </span>
            <br>    Those two questions require very different answers! Generally speaking, I set-up situations in which I improvise, often by technology. Any number of technologies from a CD player to a computer (which is probably the whole scope of it, although there are visuals as well). It tends to be centred around performative, specifically improvised approaches. This comes from what I find exciting – “nowness” and the manipulation of nowness, and how that unfolds in real-time. The bulk of what I do is oriented around that. 
                In terms of how I got started, which is a disconnected but important question: I started music when I was very young – my grandparents were piano teachers. From when I was around four I played piano. I went through the equivalent of grades (it’s a different system). As an early teenager I started playing guitar, which my family hated, but I loved it! Actually, if it wasn’t for guitar I probably would have quit music. My cousin and I had parallel lives, and the moment he turned sixteen he left the piano and never played again. It was very strict coming home every day to three hours of piano lessons. I don’t think we had a rap on the knuckles or anything, but it wasn’t far from. 
                Then, I started playing in a lot of bands. I had two parallel strands: classical music and piano, and guitar and bands. They really had nothing to do with each other. I studied more or less that way through university, then started getting in to the weirder music. The band stuff, and not too much but the piano also started leaning a bit contemporary and eventually they kind of met. Along the path of the guitar side of things I started getting into DIY guitar pedals and circuit-bending. That led into early flirtations with [inaudible]. So, a lot of what I do now came from the band strand of my background. It started off, and to a general extent, still comes from a hacky ethos. Circuit-bending was the cornerstone, and my Max stuff still falls in to that ballpark of hacky things. Then those strands merged and led to how things are now. 
                <br><br>
                <span style="font-style: italic;">When did you start playing drums? </span>
            <br>     That happened in the band era. I was around sixteen and at the time we would rehearse as a band (I was the guitar player); then we’d take a break and I would play a bit of drums, the singer would play a bit of bass, and everyone would sort of play a bit of everything. We just did that all the time. Eventually, years later when I was about twenty, a friend’s band needed a drummer. I said that I played a bit of drums and that I could join them. I didn’t even own a drum-set until I was maybe twenty-two or twenty-three! I just used other people’s drums. I didn’t have drum lessons until much later than that as well. It just kind of came as a side thing. For a whole period, I had played guitar in bands, then I was a bass player for a long time, then a drummer. I did all those roles for a while which actually ended up being very useful for the object-oriented, or instrument-specific oriented practice that I have now where the instrument isn’t just one of many. 
                <br><br>
                <span style="font-style: italic;">Do you still play guitar at all?</span>
            <br>     To a lesser degree. I was playing in a chamber ensemble a few years ago, and these days that calls for a guitar. I don’t really play guitar in bands so much these days. Same with piano or keyboard-oriented instruments. A lot of it has to do with when ten years ago I had a very profound acid trip. At that point I still associated myself with being a pianist – I played a lot of guitar and did a lot of weird music, but at my core I felt like I was an instrumentalist. Then during that I was imagining the type of music that I wanted to make which had nothing to do with a keyboard. To a lesser degree guitar fell into that, not nearly as severely, but I still thought that it wasn’t that either. So, I thought to myself, “well, what is it? Hitting things in time perhaps?” That was pretty open-ended. At that point I shifted around my priorities and started practicing more seriously and doing rudiment work which I still try to keep-up to this day to get the muscles for that up. 
                It came from the kind of thing that I wanted to do – and it meant that the instruments that I was actually most proficient at fell by the wayside. 
                <br><br>
                <span style="font-style: italic;">Do you find yourself now actively avoiding dots and pianos? </span>
            <br>     By this point I think we fairly leave each other alone. The first year of PhD was coming to terms with what notation meant and what dots mean. There’s also the whole cultural ritual and attaching it to socio-political things. I had other problems with that. For the most part I avoid it. Even the idea of notation is quite sparse at this point in what I do. And it just so happens that very little of what I do ends up involving a piano. It’s interesting because at this point my hands are definitely rustier. Until two or three years ago I still taught music theory at the college on the piano, demonstrating things and all that. Someone else has taken over that. I don’t play on a piano very often. I was doing instrumental lessons for a long time and I would be teaching on the guitar, and that doesn’t happen anymore either. I don’t physically touch these instruments too much these days. 
                <br><br>
                <span style="font-style: italic;">So, the muscle memory isn’t there anymore?</span>
            <br>     Yes. There’s probably a floor. I’m still apt, but it’s rusty. I feel it most on the piano because that’s what I was the most physically able at. If I do sit down at a piano in something like an improv class with some students, the speed and facility is definitely not there. 
                <br><br>
                <span style="font-style: italic;">With the things that you do, like networks of computers, drums, CD players and lights... And with your collaborations with Ange: in your mind are these pieces in a classical sense, or instruments, or some hybrid territory in-between?</span>
            <br>     Probably more the latter. As I was nearing the end of the PhD I was still calling them pieces. They were referred to as pieces in the paper. I was very conscious that that was something that would change and has been changing. Collectively speaking I may refer to them as a noun or an object because it makes communication easier. But I think that more than anything, I don’t think of them as contained things. Even with [the FluCoMa project] I told Pierre Alexandre that I didn’t want to do a “piece”. It’s not what I’m interested in. 
                During the talk that I did at Electric Spring, I said something along the lines of “containers”. I think that makes more sense, even though it’s still a noun. More often these days I’ll view it as something like that. I guess that some of the collaborative things with Ange fall into certain categories. So, I’ll refer to them as “one of these things” which means that we know what we’re talking about and we can explore it further. But I am wary of the “piece” idea and the noun of art. 
                <br><br>
                <span style="font-style: italic;">What role does pre-recorded, or even live-recorded audio, play in your practice?</span>
            <br>     I do have a fair number of samples on my computer, but not nearly as much as someone who works in the way that I do would. Not too much new stuff has been added to it in ten years. The new stuff that has been added comes in the form of corpora. Once I started incorporating that into my practice and what I do, that became part of it. For the most part, the software that I’ve written loads up and there’s nothing – the buffers are empty and that’s usually the starting point (except for the corpus-oriented processing: that tends to have things that don’t necessarily need to happen ahead of time but benefit from happening ahead of time).
                <br><br>
                <span style="font-style: italic;">Mostly you record the audio you need for processing as you perform?</span>
            <br>     Yes, and there are also concepts around how to deal with that and doing that so it’s not just looping. 
                <br><br>
                <span style="font-style: italic;">Are the corpora that you have attached to different projects or do they crop up when it seems fitting? </span>
            <br>     In the Party Van (the sampler that I most use when I play) there are eight corpora that are built in that I can just draw on. The stuff that I’m working on that I showed at Electric Spring has an arbitrary number of corpora – there’s sixteen-ish. They’re available at the go. Usually I will tap in to them in the context of improv. 
                <br><br>
                <span style="font-style: italic;">What’s the process of making these? Do you set out to mine a particular sound-world quite thoroughly or do you pull different things together?</span>
            <br>     It’s mixed. It’s been a while since I made one. Not long ago I prepared a toy piano, and I knew I didn’t want a highly chromatic thing. So, I did some notes and just a combination of a mish-mash of different sounds and clusters and things to give a range of sounds – but at the same time not being exhausted. Sometimes it’ll be to do with the way I’m managing the database. Sometimes bigger is good, but if for example I load up five thirty-minute corpora, then that’s going to be a problem. I may have touched on a subset of that in the Electric Spring talk: I’ve asked about six people with specific sound-worlds to contribute something that sounds like them. For me there’s something that I still haven’t fully teased-out – the [idea] of making somebody’s sound-world trivial is significant. I think it highlights the difference between the way someone sounds and the thinking process that leads to what that ends up making in the end.
                A friend of mine, who is a saxophone player, did a recording with ten close-mics with the [mechanical] sounds of air valves etc. It’s a really good corpus to have, it almost sounds like a generative version of him because it ends up sounding quite chopped anyway. I showed it to him and he said, “that’s fucking awesome, it would have saved me having to do that album!” But then again, the software would have never made that album – the thinking that led to that would have never happened. There’s something about making that – it’s the opposite of being protective about your sounds. Some people are very closed-box. It feels like a gesture to be the inverse of that. “Here are the sounds, you can literally sound like me now.” There’s for one the openness, but also trivialising the significance of that and also to a lesser extent pushing me, or whoever, further. The way that you sound is no longer meaningful, significant or unique. 
                <br><br>
                <span style="font-style: italic;">Did he give you a continuous recording which you cut up? </span>
            <br>     He was busy at the time, so I basically took his album, took some material that I thought was significant, and he sent me some newer things that he was working on. All together it made about ten minutes. I spoke to others like John Oswald and asked him if it was cool to use Plexure which is just micro-sample stuff, and he said that it was OK. It was nice to talk to him because he had somehow come across the Party Van and he was into it. In some cases, like that, it was pillaging of pillaged material. But yes, in other cases someone will send me a big recording. There’s minimum remove silence depending on how tidy they are. Some people just hit record and play for forty minutes and they’ll send me a whole whopping thing. I trim down. Most of my corpora are between ten and fifteen minutes. When I did a lot of them, I figured that that was a good useable range. 
                <br><br>
                <span style="font-style: italic;">Do you feed your system the whole big file on which it runs descriptors over?</span>
            <br>     Yes. When I first started doing this kind of thing in 2011, 2012, it was easier [to chop it up into gestures]. I found CataRT to be very overwhelming. 
                <br><br>
                <span style="font-style: italic;">How long have you been working with descriptors?</span>
            <br>     Even before I started doing the cocat stuff. In 2011 I decided to shift from a hardware-based thing to a software-based thing. I doubled down in Max – I’d been messing around in Max on and off for a long time [but it’s now a big part of my performance]. At that early stage I’d been playing live, and I already had a sort of practice – so, I came at it with a fairly mature conceptual idea of what I wanted. I knew that I didn’t want to micromanage. I didn’t have the physical or mental headspace to mess with parameters and knobs and sliders – that wasn’t possible in what I wanted to do. Particularly seeing as it was technology in conjunction with an instrument. I ended up choosing a modern controller – I figured that muscle memory from keyboard playing would be useful. Around that time, I actually came out with a knob one. Then, I basically made audio analysis-driven preset generation. If I turned on an effect or some kind of processing it had settings that were based on an analysis of what had been happening in the audio at the time. At the time I spent a long time fine-tuning them. The code looks horrifying because I had one central descriptors RT that spits out fifteen different descriptors. Each descriptor ran through smoothing – I had small, medium and large versions of scales of time. In the algorithms and also in the patch I can tap into any one of these strands. It’s what I did for each parameter. I based it on the distortion, gain setting, the centroid of this, medium of this... They were just sorts of hacky, number-crunchy things to spit out a number. So, I was doing a lot of things along those lines at first. 
                <br><br>
                <span style="font-style: italic;">Quite a lot of fine-tuning?</span>
            <br>     Yes, and letting the audio analysis handle the detailed work for me. Not necessarily random but informed by what was happening. 
                <br><br>
                <span style="font-style: italic;">Did you find it quite easy to build an intuitive relationship with those descriptors across different bodies of material?</span>
            <br>     To a certain extent. At the time, [for example] I would turn on an effect and I knew that I was going to get distortion, and different flavours of that. It wasn’t a radically different thing when I pushed a button. However, it handled a lot of the detailed work for me. Still related to improv and my own practice, the material going in to it didn’t vary wildly other than what I knew was going in to it. If I was using a different instrument that day, I would get a known-ish [result]. 
                <br><br>
                <span style="font-style: italic;">Is there anything when working now with this descriptor-based stuff that feels frustrating or gooey to you? </span>
            <br>     The thing that I’d want to improve the most is that it doesn’t translate too well to onset-based material. On top of that, at the end of the day, it’s all granular synthesis which has a [certain] sound. Part of what I was doing when building the combine thing that I showed, was not segmentation, but tagging grains as onsets and ones that aren’t etc. Finally, I thought that I should wait as you guys would do it better than me. So, being able to have onset-based re-synthesis that doesn’t just sound like [crunchy sound]. 
                <br><br>
                <span style="font-style: italic;">In these systems that you make, what seems to be the gestural relationship between you and the computer? Is it quite direct of does the computer sometimes go off and start making its own gestural shapes? </span>
            <br>     It tends to be direct, although some of it ends up not being so because of bad mapping – but at this point, bad mapping on purpose. In the very first version I did of this, the playback and analysis windows were asynchronous – or rather not the same. So, even if it was direct mapping, what I would get out would be more auto accompaniment-ish things. So, even doing it better now, I still build that in, so I can tap in to that and still have that. For the most part, it isn’t a full AI thing, if I stop then the computer will stop as well in the scope of that type of process. 
                <br><br>
                <span style="font-style: italic;">When going through things, trimming down to make a corpus, do you have tricks and tactics to find the good stuff? Do you look for relationships between sounds in quite a conscious way?</span>
            <br>     I tend to work things out in the actual act of, not performance, but performative music-making – I aim to make adjustments there. Of course, if it really isn’t working then I’ll return to the code – there’s a certain threshold. Before that I’ll try and find musical solutions as opposed to technical ones. I have started thinking about that because I’ve started getting into modular stuff. Going to that from having a performance practice – I’m dubious of sweet spots, or a parametric fetishization of “sweet spot-ness”. For example, if a certain sample will behave a certain way with a certain input, that’s novel within the scope of the processing that’s happening, but is it novel within the scope of aesthetics, or just listening? For example, these processes don’t usually do this, but in this unusual use-case they do. In the geeky sense that’s awesome, but in the non-geeky sense, does it matter? Does it sound interesting? I tend to be not very oriented around sweet spot-ness in terms of programming. 
                How did you come to develop the capacity to know when to stop coding and when to start music-making? 
                The early days of the Party Van were when I started doing that more. It worked and functioned, then I’d go into a rehearsal (I was rehearsing with Pierre Alexandre) and as it was happening I would notice [things] and I would make notes. Often there would be things that were broken, but I would also make notes noting that I would want to be able to do a certain thing, but I couldn’t. Then I’d go away and code stuff. However, at some point I realised that those things shifted. I left things that weren’t bugs more alone. When something didn’t do what I wanted, I would think about what the musical solution could be. It became an innovative process that led to those decisions. 
                <br><br>
                <span style="font-style: italic;">These days, when I use what I have it requires much less note-taking. Things are more or less stable enough and don’t have huge glaring bugs. I know where I’m going with some of the stuff – but I will occasionally make notes still. 
            How did you build up your relationship with Max?</span>
            <br>     I basically started with Max tutorials. A friend had a friend who knew someone who was studying computer music in school who gave me and a friend of ours a couple of Max lessons of about thirty or forty minutes. At the beginning, I’d do the tutorials in a really hardcore way for about six months, and then I’d quit. Then a year later I’d do the same thing. I was primarily interested in more or less what I’m doing now – live-processing and live-sampling – which isn’t very easy to do in Max when you start off. If [for example] you want to just record someone and play it back, that’s a mess of things that you need to learn how to do. It took me a long time to get there. 
                I basically had a set-up that I was using: a hardware sampler and some effects. I was planning to do an iteration of that to have more complex control of all sorts of things. I had a sketchbook full of ideas – a custom [inaudible] thing, LCDs etc. I realised that it would probably be easier to do it in Max. So, I learnt it a bit more, and set-out literally trying to recreate my set-up in Max. I started that way, then it was a very steep uphill push to get to a point where I was able to have some kind of sampling and playback that worked in real-time in a way I was happy with. Once that happened, it was part of my performance set-up and I just carried on developing it from there. It took a big push to get there. At the time the forums were more active so there was some help there, and a few people were very helpful with sitting down with me and [explaining things]. I also sat down with Alex and Pierre Alexandre and they helped quite a bit. I have had quite a few code-mentors along the way. 
                I was grateful. Particularly in a language like Max (even though I haven’t gone through the tutorials in a long time) a lot of things just don’t exist like ideas and concepts that have nowhere to go. 
                <br><br>
                <span style="font-style: italic;">How did you learn about descriptor stuff?</span>
            <br>     I think I had some of Alex’s objects and started playing with them – not in a very meaningful way. I just copied out the help file and wrote in a sketchbook what every descriptor did. I didn’t have a very academic understanding. I understood what it did, but it didn’t mean too much. Things like “roughness” didn’t really mean too much – I wasn’t scaling it properly, and a lot of other things. A lot of things didn’t seem to make sense. 
                Another thing that I’m tending to realise now, I still approach things from a very hacky way. I was talking to a friend who is working on something where he iterates over white noise mp3 processing to try and extract music. It’s kind of a cool idea. He’s using python and C++ to do this stuff. It’s a cool idea, but probably is something that would never occur to me – to build a toolset to do that is not really in my forte at all. I don’t necessarily work that way. I’ll just hack at this, and then another thing etc.
                <br><br>
                <span style="font-style: italic;">You prefer to have something that’s there that you can start playing with quite quickly? </span>
            <br>     Yes. 
                <br><br>
                <span style="font-style: italic;">It sounds like you’re building up a relationship that is led more aurally rather than textually or mathematically. </span>
            <br>    Yes. For example, Alex’s externals: the help files are fairly thorough, but they’re also relatively abstract. Entrymatcher actually communicated very little about what it means to use it in context. I’ve [told him off] many times over the years about how useless that help file is, at least for me. I found it quite confusing. It took sitting down with him or looking at someone else’s patch to make things clear. The help file itself contains all of that information, but it’s abstracted. It’s more a reference file than a help file.
                <br><br>
                <span style="font-style: italic;">How long did it take you to make friends with entrymatcher? </span>
            <br>     I don’t do a tremendous amount with it, but it was basically having a simple version of early concat stuff. I wrapped my head around that, then when Alex was over in Spain last summer, he did a push towards 2.0. It does a lot more things now. But I don’t use it in a very sophisticated way. 
                <br><br>
                <span style="font-style: italic;">I noticed at Electric Spring that your patch was so tidy. You’d clearly spent some time, once the thing was finished, making sure that it was quite easy to read. Is that a constant part of your development cycle?</span>
            <br>     Yes. I tend, to a certain extent, to tidy up as I go. Once something is at an abstraction [inaudible] level, I’ll tend to tidy that chunk up and move on. It’s better for me for when I come back [for example]. That way I also know that code that I make will be sharable. I imagine that that is useful to other people, in terms of being able to open it and [understand immediately what’s happening]. 
                <br><br>
                <span style="font-style: italic;">Is that partly due to a traumatic experience of having opened something like CataRT for the first time?</span>
            <br>     Yes, that particularly is unimaginable. But even other things like early [inaudible] stuff and literally having no idea about what’s going on. Ryan is a great programmer, but his Max patches are terrifying. Opening something like that and literally having no idea about anything that’s going on. I’m not wanting to do that. A lot of the best patches that I’ve worked with are Alex’s, and I guess I’ve picked up his style which is a little more OCD. 
                <br><br>
                <span style="font-style: italic;">Do you manage to maintain a discipline of making notes throughout your practice?</span>
            <br>     I have an OmniFocus to-do thing. I don’t manage the getting things done aspect of it, it’s basically just a repository. I’m quite organised with that, and it just comes to do with my general disposition. If I have an idea in my head, until the point that I’ve written it down, it will bother me. I’m quite detailed with it: I’ll have chunks of code in the comments section. I tend to be quite organised in terms of what I want to do next and ideas for the future.
                <br><br>
                <span style="font-style: italic;">Do you tend to keep notes on reflections on playing? </span>
            <br>     That, less often, but I did do a big improv-analysis oriented thing as part of my PhD, so that’s a more formalised version of that. It’s very useful, and I do want to do more of that and return to that idea. But if I do a gig, I don’t necessarily sit down and write something about it. But I will generally talk about it – I’ll talk to Ange after our performances, also when we watch other performances I find it to be useful.
                <br><br>
                <span style="font-style: italic;">Do you ever find that acquiring a more academic understanding of things like descriptors would be useful for your practice or is it just a parallel body of knowledge that has nothing to do with music? </span>
            <br>     It’s something I want to do. I think it’s one of those grass is greener things: all programmers wish they were engineers and all engineers wish they were musicians. I’m in a funny place now, because I’m an OK enough programmer that starting C++ tutorials feels very useless. I understand stuff like that. But it is something I want to learn more of. 
                <br><br>
                <span style="font-style: italic;">Have you tried any of Alex’s new stuff like the framelib or anything like that? </span>
            <br>     The biggest part of that has come out since I’ve moved. [...] In terms of the general idea of it I haven’t really done anything with it.
                <br><br>
                <span style="font-style: italic;">Is it because the blocks seem quite low-level, a bit abstract?</span>
            <br>     Yes, coming from my background in education, I didn’t have too much formalised computer music stuff. My master’s was in electroacoustic composition, but there’s kind of an FFT sized hole in my knowledge. There are things like this that I do want to fill in a bit more and be able to make better use of things like that. 
        </p>

    </div>

    <script src="/scripts/collapsables.js"></script>

</body>
</html>